# ===========================
# Docker Deployment Configuration
# ===========================
# Copy this file to .env and fill in your values

# Server Configuration
NODE_ENV=production
PORT=3000

# CORS Configuration
# Comma-separated list of allowed origins
# Examples:
#   Single origin: https://your-domain.com
#   Multiple origins: https://your-domain.com,https://app.your-domain.com
#   All origins (NOT recommended): *
ALLOWED_ORIGINS=http://localhost:3000

# Rate Limit Configuration (Optional)
# Defaults are configured for 20 parallel workers
# Increase if you need more concurrent operations
RATE_LIMIT_LLM_MAX=1000      # LLM requests per minute
RATE_LIMIT_API_MAX=10000     # API requests per 15 minutes

# ===========================
# LLM Provider Configuration
# ===========================
# Options: openai, b-api-openai, b-api-academiccloud
# Default: b-api-openai
# - openai: Direct OpenAI API (requires OPENAI_API_KEY)
# - b-api-openai: B-API OpenAI-compatible endpoint (requires B_API_KEY)
# - b-api-academiccloud: B-API AcademicCloud with DeepSeek-R1 (requires B_API_KEY)
LLM_PROVIDER=b-api-openai

# ===========================
# Option 1: OpenAI Configuration
# ===========================
# Required if LLM_PROVIDER=openai
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-your-key-here

# ===========================
# Option 2: B-API Configuration
# ===========================
# Required if LLM_PROVIDER=b-api-openai or b-api-academiccloud
B_API_KEY=your-b-api-key-here

# OpenAI Model (Optional)
# Default: gpt-4.1-mini
# Options: gpt-5-mini, gpt-5-nano, gpt-5, gpt-4.1-mini, gpt-4o, gpt-4o-mini, gpt-4-turbo, etc.
OPENAI_MODEL=gpt-4.1-mini

# ===========================
# Security Notes
# ===========================
# ⚠️  IMPORTANT:
# - NEVER commit .env file to Git
# - Keep API keys secret
# - Use strong passwords for B-API
# - Limit ALLOWED_ORIGINS in production
# - Use HTTPS in production
# - Consider using Docker secrets for sensitive data
